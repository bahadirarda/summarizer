import logging
from datetime import datetime
from pathlib import Path
from typing import Optional, Any
import re
import sys
import subprocess
import urllib.parse
import time

from .file_tracker import (  # Import for getting changed files
    get_changed_files_since_last_run,
    get_file_line_changes,
    get_aggregate_line_stats,
    create_file_backups,
)
from .json_changelog_manager import JsonChangelogManager, ImpactLevel, ChangeType
from .readme_generator import update_readme
from .version_manager import VersionManager
from .git_manager import GitManager, SyncStatus, _ask_user

logger_changelog = logging.getLogger(__name__)


def _detect_impact_level(summary: str, changed_files: list) -> ImpactLevel:
    """Auto-detect impact level based on summary and files"""
    summary_lower = summary.lower()

    # Critical indicators
    critical_keywords = [
        "critical",
        "hotfix",
        "security"]
    if any(keyword in summary_lower for keyword in critical_keywords):
        return ImpactLevel.CRITICAL

    # High impact indicators
    high_keywords = ["major", "breaking", "api"]
    if any(keyword in summary_lower for keyword in high_keywords):
        return ImpactLevel.HIGH

    # Low impact indicators
    low_keywords = ["typo", "docs", "readme"]
    if any(keyword in summary_lower for keyword in low_keywords):
        return ImpactLevel.LOW

    # Based on file count
    if len(changed_files) > 10:
        return ImpactLevel.HIGH
    elif len(changed_files) <= 2:
        return ImpactLevel.LOW

    return ImpactLevel.MEDIUM


def _run_ci_checks(project_root: Path) -> bool:
    ci_script_path = project_root / "scripts" / "run_ci_checks.py"
    if not ci_script_path.exists():
        print(f"   âŒ CI script not found at {ci_script_path}")
        return False
    # Pass '-s' to pytest to disable output capture, allowing interactive prompts if necessary for testing
    ci_process = subprocess.run([sys.executable, str(ci_script_path), '-s'], cwd=project_root)
    if ci_process.returncode == 0:
        print("   âœ… All CI checks passed.")
        return True
    else:
        print("   âŒ CI checks failed.")
        return False


def _write_next_command(project_root: Path, command: str):
    command_file_path = project_root / ".summarizer" / "next_command.sh"
    try:
        with open(command_file_path, "w") as f: f.write(f"{command}\n")
        print(f"   âœ¨ Next step command generated: {command}")
    except Exception as e:
        logger_changelog.error(f"Could not create next_command.sh file: {e}")


def _extract_pr_number(pr_url: str) -> Optional[int]:
    """Extract PR number from GitHub PR URL"""
    try:
        # URL format: https://github.com/owner/repo/pull/123
        parts = pr_url.strip().split('/')
        if 'pull' in parts:
            pr_number = int(parts[-1])
            return pr_number
    except:
        pass
    return None


def _handle_pull_request_flow(project_root: Path, git_manager: GitManager, current_branch: str, target_branch: str, summary: str, gemini_client: Any = None, auto_create: bool = True):
    """Handles the pull request creation/update process intelligently and offers next steps."""
    print("   â±ï¸  Checking for existing PRs and remote branches...")
    if not git_manager.remote_branch_exists(target_branch):
        print(f"   âŒ Target branch '{target_branch}' does not exist on the remote. Please push it first.")
        return
    
    git_manager.fetch_updates()
    
    existing_pr = git_manager.get_existing_pr(current_branch)
    current_version = VersionManager(project_root).get_current_version()
    
    # Better PR title based on branch type
    branch_type = current_branch.split('/')[0] if '/' in current_branch else 'update'
    pr_title = f"{branch_type}: v{current_version} - {current_branch.split('/')[-1] if '/' in current_branch else 'update'}"
    
    if existing_pr:
        print(f"   âœ… An open pull request already exists: {existing_pr['url']}")
        
        # Check if there are new commits to push
        sync_status, ahead, behind = git_manager.get_branch_sync_status(current_branch)
        
        if sync_status == SyncStatus.AHEAD:
            # Only push if we have unpushed commits
            if _ask_user(f"   â” Push {ahead} new commit(s) to the existing PR?"):
                print(f"   ðŸš€ Pushing new commits to '{current_branch}'...")
                push_success, _ = git_manager.push(current_branch)
                if push_success:
                    print("   âœ… Successfully pushed new commits to the existing PR.")
                    print(f"   ðŸ“Ž PR URL: {existing_pr['url']}")
                else:
                    print("   âŒ Failed to push updates to the PR branch.")
        else:
            print(f"   âšªï¸ No new commits since last push. PR is up to date.")
            print(f"   ðŸ“Ž PR URL: {existing_pr['url']}")
    else:
        # Check if branch has been pushed
        if not git_manager.remote_branch_exists(current_branch):
            print(f"   âš ï¸  Branch '{current_branch}' has not been pushed to remote yet.")
            return
        
        # If auto_create is True (from AI workflow), create PR automatically
        # Otherwise ask the user
        should_create = auto_create or _ask_user(f"   â” Create a new Pull Request from '{current_branch}' to '{target_branch}'?")
        
        if should_create:
            print("   ðŸ¤– Generating AI-powered pull request details...")
            new_body = git_manager.generate_pull_request_body(summary, gemini_client)
            print(f"   ðŸ“ PR Title: {pr_title}")
            pr_url = git_manager.create_pull_request(title=pr_title, body=new_body, base_branch=target_branch, head_branch=current_branch)
            if pr_url:
                print(f"   âœ… Successfully created Pull Request: {pr_url}")
                
                # Check if PR has conflicts after creation
                print("   ðŸ” Checking for potential conflicts...")
                pr_number = _extract_pr_number(pr_url)
                if pr_number:
                    try:
                        import subprocess
                        import json
                        conflict_cmd = ["gh", "pr", "view", str(pr_number), "--json", "mergeable,mergeStateStatus"]
                        conflict_process = subprocess.run(
                            conflict_cmd,
                            cwd=project_root,
                            capture_output=True,
                            text=True,
                            check=True
                        )
                        
                        conflict_data = json.loads(conflict_process.stdout)
                        
                        if conflict_data.get('mergeable') == 'CONFLICTING':
                            print("   âš ï¸  WARNING: This PR has merge conflicts!")
                            print("   ðŸ“ Conflicts need to be resolved before merging.")
                            
                            # Offer to resolve conflicts automatically
                            if _ask_user("\n   â” Would you like to try resolving conflicts automatically?"):
                                if git_manager.resolve_conflicts_with_pr(pr_number):
                                    print("\n   ðŸŽ‰ Conflicts resolved successfully!")
                                    print("   ðŸ“‹ The PR has been updated and is ready for review.")
                                else:
                                    print("   âŒ Automatic conflict resolution failed.")
                                    print("   ðŸ’¡ Please resolve conflicts manually:")
                                    print("      â€¢ Use GitHub web editor, or")
                                    print("      â€¢ Pull latest changes from target branch and resolve locally")
                        elif conflict_data.get('mergeStateStatus') == 'BLOCKED':
                            print("   âš ï¸  PR is blocked (required checks not passed)")
                    except Exception as e:
                        # Don't fail if conflict check fails
                        print(f"   âš ï¸  Could not check PR status: {e}")
            else:
                print("   âŒ Failed to create Pull Request.")


def _handle_release_creation(project_root: Path, git_manager: GitManager, new_version: str):
    release_branch_name = f"release/v{new_version}"
    if _ask_user(f"   â” Run CI checks and create release branch '{release_branch_name}'?"):
        if not _run_ci_checks(project_root):
            if not _ask_user("   âš ï¸  CI checks failed. Create branch anyway?"):
                return
        if git_manager.create_branch(release_branch_name):
            _write_next_command(project_root, f"git checkout {release_branch_name}")
        else:
            print(f"   âš ï¸  Could not create release branch '{release_branch_name}'.")


def _post_workflow_sync(git_manager: GitManager):
    """After a workflow, offers a safe, professional, and context-aware way to sync the local repo."""
    print("\n" + "="*50 + "\n   ðŸš€ Workflow Complete\n" + "="*50)
    
    # Just sync current branch, don't offer dangerous merges
    current_branch = git_manager.get_current_branch()
    print(f"\n   ðŸ”Ž Checking sync status for current branch '{current_branch}'...")
    
    status, ahead, behind = git_manager.get_branch_sync_status(current_branch)
    if status == SyncStatus.SYNCED:
        print(f"   âœ… Branch '{current_branch}' is in sync with remote.")
    elif status == SyncStatus.AHEAD:
        if _ask_user(f"   â” Your branch is {ahead} commit(s) ahead. Push remaining changes?"):
            git_manager.push(current_branch)
    elif status == SyncStatus.BEHIND:
        if _ask_user(f"   â” Your branch is {behind} commit(s) behind. Pull latest changes?"):
            git_manager.pull(current_branch)
    elif status == SyncStatus.DIVERGED:
        print(f"   âš ï¸  Branch '{current_branch}' has diverged from the remote. You have unique local and remote commits.")
        print("   ðŸ’¡ This requires manual intervention. Your options:")
        print("      1. 'git pull' - to merge remote changes into your local branch (may cause conflicts).")
        print("      2. Force push - to overwrite the remote branch with your local changes (DANGEROUS).")
        
        if _ask_user("\n   â” Do you want to attempt a force push to resolve the divergence?"):
            git_manager.force_push_with_confirmation(current_branch)
    
    print("\n   ðŸ“‹ Workflow Summary:")
    print(f"   â€¢ Current branch: {current_branch}")
    print("   â€¢ All changes have been processed")
    print("   â€¢ Remember: Use PRs for merging to protected branches")


def _handle_git_workflow(project_root: Path, git_manager: GitManager, new_version: str, summary: str, gemini_client: Any):
    """Handle additional git workflow after main processing - simplified version"""
    current_branch_name = git_manager.get_current_branch()
    
    # Only handle if there are uncommitted changes (edge case)
    if not git_manager.is_working_directory_clean():
        print(f"\n   ðŸ“‚ Additional changes detected on '{current_branch_name}'...")
        if _ask_user("   â” Stage and commit these additional changes?"):
            git_manager.stage_all()
            commit_message = f"feat(summarizer): Additional changes for v{new_version}"
            if git_manager.commit(commit_message):
                print("   âœ… Additional changes committed.")
                if _ask_user("   â” Push these additional changes?"):
                    git_manager.push(current_branch_name)
    
    # Show final sync status
    _post_workflow_sync(git_manager)


def update_changelog(project_root: Optional[Path] = None):
    """Update changelog with AI-generated summaries using JSON format"""
    if project_root is None:
        project_root = Path(__file__).resolve().parent.parent.parent
        logger_changelog.warning(
            f"project_root not provided to update_changelog, guessed as {project_root}")

    # Initialize JSON changelog manager
    json_manager = JsonChangelogManager(project_root)

    # Get changed files - check for different possible source directories
    changed_files = []
    try:
        print("   ðŸ” Scanning for changed files...")
        # Use dynamic directory discovery (no manual directory specification needed)
        changed_files = get_changed_files_since_last_run(project_root)
        print(f"   ðŸ“‚ Dynamically scanning all Python directories")

        if changed_files:
            print(f"   âœ… Found {len(changed_files)} changed files:")
            for file in changed_files:
                print(f"      â€¢ {file}")
            logger_changelog.info(
                f"Detected changed files since last run: {changed_files}"
            )
        else:
            print("   ðŸ“ No file changes detected")
            logger_changelog.info("No file changes detected since last run.")
            # Check if this is a new project that needs initialization
            changelog_file = project_root / "CHANGELOG.md"
            json_file = project_root / "changelog.json"
            
            if not changelog_file.exists() or not json_file.exists():
                print("   ðŸŽ‰ Initializing new project...")
                logger_changelog.info("Initializing new project with welcome entry.")
                _create_initial_project_entry(json_manager, project_root)
                return
            else:
                print("   âœ… Project up to date - no changes to track")
                # No changes in existing project
                return
    except Exception as e:
        logger_changelog.error(
            f"Error detecting changed files for changelog: {e}", exc_info=True
        )
        # Return if there's an error, don't create fake entries
        return

    # Analyze line changes
    line_changes = {}
    total_lines_added = 0
    total_lines_removed = 0

    try:
        print("   ðŸ“Š Analyzing line changes...")
        line_changes = get_file_line_changes(project_root, changed_files)
        aggregate_stats = get_aggregate_line_stats(line_changes)
        total_lines_added = aggregate_stats["total_lines_added"]
        total_lines_removed = aggregate_stats["total_lines_removed"]

        print(f"   ðŸ“ˆ Line changes: +{total_lines_added} added, -{total_lines_removed} removed")

        logger_changelog.info(
            f"Line changes analysis: +{total_lines_added} -{total_lines_removed} "
            f"across {len(changed_files)} files"
        )

    except Exception as e:
        print("   âš ï¸  Could not analyze line changes")
        logger_changelog.error(
            f"Error analyzing line changes: {e}",
            exc_info=True)

    # Get AI summary using RequestManager
    try:
        print("   ðŸ¤– Generating AI analysis...")
        from ..services.request_manager import RequestManager

        request_manager = RequestManager()
        gemini_client = request_manager.get_client("GeminiClient")
    except ValueError:
        print("   âš ï¸  AI client not available")
        logger_changelog.warning("GeminiClient not found in RequestManager.")
        gemini_client = None

    summary = "Genel gÃ¼ncelleme."
    impact_level = ImpactLevel.MEDIUM
    change_type = ChangeType.OTHER

    if gemini_client and gemini_client.is_ready():
        try:
            prompt = f"DeÄŸiÅŸen dosyalar: {', '.join(changed_files)}"
            ai_summary = gemini_client.generate_summary(
                text_prompt=prompt, changed_files=changed_files
            )
            summary = ai_summary
            print("   âœ¨ AI analysis completed successfully")
            print(f"   ðŸ“ Summary: {summary[:100]}{'...' if len(summary) > 100 else ''}")
            logger_changelog.info(f"AI tarafÄ±ndan oluÅŸturulan Ã¶zet: {summary}")

            # Auto-detect impact level based on summary and files
            impact_level = _detect_impact_level(ai_summary, changed_files)
            print(f"   ðŸŽ¯ Impact level: {impact_level.value}")

        except Exception as e:
            print("   âš ï¸  AI analysis failed, using fallback")
            logger_changelog.error(
                f"GeminiClient'tan Ã¶zet alÄ±nÄ±rken hata oluÅŸtu: {e}",
                exc_info=True)
            summary = "AI Ã¶zeti alÄ±namadÄ±. DeÄŸiÅŸiklikler uygulandÄ±."
    else:
        print("   âš ï¸  AI client unavailable, using default summary")
        logger_changelog.warning(
            "GeminiClient kullanÄ±lamÄ±yor. VarsayÄ±lan Ã¶zet kullanÄ±lÄ±yor."
        )

    # Add entry to JSON changelog
    print("   ðŸ’¾ Saving changelog entry...")
    entry_id = json_manager.add_entry(
        ai_summary=summary,
        changed_files=changed_files,
        impact_level=impact_level,
        change_type=change_type,
        lines_added=total_lines_added,
        lines_removed=total_lines_removed,
    )

    print(f"   âœ… Changelog entry created (ID: {entry_id[:8]}...)")
    logger_changelog.info(f"Changelog entry added with ID: {entry_id}")

    # Create backups for next run comparison
    try:
        print("   ðŸ”„ Creating backup files for future comparison...")
        create_file_backups(project_root, "src" if (project_root / "src").exists() else ".")
        print("   âœ… Backup files created")
        logger_changelog.debug("File backups created for future line analysis")
    except Exception as e:
        print("   âš ï¸  Could not create backup files")
        logger_changelog.error(
            f"Error creating file backups: {e}",
            exc_info=True)

    # Update README.md automatically with AI enhancement
    try:
        print("   ðŸ“ Updating README.md with current project state...")
        
        # Get AI client for README enhancement
        ai_client = None
        try:
            from ..services.request_manager import RequestManager
            request_manager = RequestManager()
            ai_client = request_manager.get_client("GeminiClient")
        except:
            pass  # Continue without AI enhancement
            
        readme_updated = update_readme(project_root, ai_client)
        if readme_updated:
            print("   âœ… README.md automatically updated")
        else:
            print("   âš ï¸  README.md update skipped")
            
    except Exception as e:
        print(f"   âš ï¸  Could not update README.md: {e}")
        logger_changelog.error(f"Error updating README.md: {e}", exc_info=True)

    # Professional Version Management
    try:
        print("   ðŸ·ï¸  Analyzing changes for version management...")
        version_manager = VersionManager(project_root)
        git_manager = GitManager(project_root)

        # Determine increment type based on impact level ONLY. This is the single source of truth.
        increment_type = "patch"
        if impact_level == ImpactLevel.CRITICAL:
            increment_type = "major"
        elif impact_level == ImpactLevel.HIGH:
            increment_type = "minor"
        elif impact_level == ImpactLevel.MEDIUM:
            increment_type = "minor"

        # Use the new centralized incrementer
        new_version, old_version = version_manager.auto_increment(increment_type)

        if new_version != old_version and version_manager.update_version_in_files(new_version):
            print(f"   ðŸ“ˆ Version updated: {old_version} â†’ {new_version}")
            print(f"   ðŸŽ¯ Change Impact: {impact_level.value} ({increment_type} increment)")

            # Get version codename
            major, minor, _ = version_manager.parse_version(new_version)
            codename = version_manager._get_version_codename(major, minor, new_version, gemini_client)
            if codename:
                print(f"   ðŸ’« Codename: {codename}")
                
            # Create git tag for new version
            try:
                version_manager.create_git_tag(new_version, codename=codename)
                print(f"   ðŸ·ï¸  Git tag created: v{new_version}")
            except Exception as tag_error:
                print(f"   âš ï¸  Could not create git tag: {tag_error}")

            # Get AI workflow decision
            current_branch_name = git_manager.get_current_branch()
            print("\n   ðŸ¤– Consulting AI for workflow optimization...")
            workflow_decision = _get_ai_workflow_decision(gemini_client, current_branch_name, summary, impact_level, changed_files)
            
            print(f"   ðŸŽ¯ AI Recommendation: {workflow_decision['reasoning']}")
            
            # Handle branch creation if recommended
            if workflow_decision['recommended_branch'] != 'current' and workflow_decision['recommended_branch'] != current_branch_name:
                recommended_branch = workflow_decision['recommended_branch']
                if _ask_user(f"   â” AI suggests creating branch '{recommended_branch}'. Create it?"):
                    if git_manager.create_branch(recommended_branch):
                        git_manager.checkout(recommended_branch)
                        current_branch_name = recommended_branch
                        print(f"   âœ… Switched to recommended branch: {recommended_branch}")
                    else:
                        print(f"   âš ï¸  Could not create recommended branch. Continuing on {current_branch_name}")
            
            # Pre-commit CI checks for main/develop branches
            if current_branch_name in ['main', 'develop', 'staging']:
                print(f"\n   ðŸ”¬ Running pre-commit CI checks for '{current_branch_name}' branch...")
                if not _run_ci_checks(project_root):
                    if not _ask_user("   âš ï¸  CI checks failed. Continue with commit anyway?"):
                        print("   âšªï¸ Commit aborted by user.")
                        # Revert version bump if commit is aborted
                        version_manager.update_version_in_files(old_version)
                        print(f"   âª Version reverted to {old_version}.")
                        return
                    print("   âšªï¸ CI checks failed, but proceeding with commit as requested.")
                else:
                    print("   âœ… Pre-commit CI checks passed.")

            # Commit changes to git
            if not git_manager.is_working_directory_clean():
                prompt_message = f"   â” Commit changes to '{current_branch_name}'?"
                if _ask_user(prompt_message):
                    commit_message = f"chore(summarizer): Auto-update to v{new_version}\n\n{summary}"
                    if not (git_manager.stage_all() and git_manager.commit(commit_message)):
                        print("   âŒ Failed to commit changes. Aborting.")
                        return

            # Follow AI-recommended workflow
            if workflow_decision['workflow'] == 'pr':
                # Create PR to target branch
                target_branch = workflow_decision.get('target_branch', 'develop')
                
                if _ask_user(f"   â” Push '{current_branch_name}' to GitHub and create PR to '{target_branch}'?"):
                    success, output = git_manager.push(current_branch_name)
                    if success:
                        print("   âœ… Branch pushed to GitHub successfully.")
                        # Now handle PR creation/update
                        _handle_pull_request_flow(project_root, git_manager, current_branch_name, target_branch, summary, gemini_client)
                        
                        # Info about main branch protection
                        if target_branch in ['main', 'master']:
                            print("\n   ðŸ”’ Note: This PR targets the MAIN branch.")
                            print("   ðŸ“‹ The PR will need to be reviewed and approved before merging.")
                            print("   ðŸ’¡ Merge protection is enforced on the main branch.")
                    else:
                        print(f"   âŒ Push failed: {output}")
            elif workflow_decision['workflow'] == 'direct':
                # Direct push (only for non-protected branches)
                if current_branch_name not in ['main', 'master']:
                    if _ask_user(f"   â” Push changes directly to '{current_branch_name}' on GitHub (no PR)?"):
                        success, output = git_manager.push(current_branch_name)
                        if success:
                            print("   âœ… Changes pushed directly to GitHub.")
                        else:
                            print(f"   âŒ Push failed: {output}")
                else:
                    print("   âŒ Direct push to main/master branch is not allowed!")
                    print("   ðŸ’¡ Please create a release or hotfix branch instead.")
            elif workflow_decision['workflow'] == 'release':
                # Special release workflow
                print("   ðŸ“¦ Following release workflow...")
                if _ask_user(f"   â” Push '{current_branch_name}' to GitHub and create release PR to 'main'?"):
                    success, output = git_manager.push(current_branch_name)
                    if success:
                        print("   âœ… Release branch pushed to GitHub.")
                        # Now handle PR creation for release
                        _handle_pull_request_flow(project_root, git_manager, current_branch_name, 'main', summary, gemini_client)
                    else:
                        print(f"   âŒ Push failed: {output}")

    except Exception as e:
        print(f"   âš ï¸  Version management failed: {e}")
        logger_changelog.error(f"Error in version management: {e}", exc_info=True)

    # Hand off to the master Git workflow handler
    _handle_git_workflow(project_root, git_manager, new_version, summary, gemini_client)


def _create_initial_project_entry(json_manager, project_root: Path):
    """Create professional initial project entry for new projects"""
    
    # Create hidden project structure
    summarizer_dir = project_root / ".summarizer"
    summarizer_dir.mkdir(exist_ok=True)
    
    # Detect project type
    project_type = _detect_project_type(project_root)
    project_name = project_root.name
    
    # Professional welcome message based on project type
    if project_type == "python":
        welcome_summary = f"""ðŸš€ **{project_name} Projesi BaÅŸlatÄ±ldÄ±**

**Proje TÃ¼rÃ¼**: Python Projesi  
**BaÅŸlatÄ±lma Tarihi**: {datetime.now().strftime('%d %B %Y')}  
**Summarizer Framework**: v2.0.0

**ðŸ“‹ Proje Ã–zeti:**
Bu proje, Summarizer Framework ile otomatik deÄŸiÅŸiklik takibi ve AI destekli analiz iÃ§in yapÄ±landÄ±rÄ±ldÄ±. ArtÄ±k kod deÄŸiÅŸiklikleriniz otomatik olarak tespit edilecek ve akÄ±llÄ± Ã¶zetler oluÅŸturulacak.

**ðŸ”§ Aktif Ã–zellikler:**
- âœ… Otomatik dosya deÄŸiÅŸiklik takibi
- âœ… AI destekli kod analizi (Gemini AI)
- âœ… JSON ve Markdown changelog oluÅŸturma
- âœ… Etki seviyesi ve deÄŸiÅŸiklik tipi otomatik tespiti
- âœ… SatÄ±r bazÄ±nda deÄŸiÅŸiklik analizi

**ðŸ“ OluÅŸturulan Dosyalar:**
- `CHANGELOG.md` - Ä°nsan okunabilir deÄŸiÅŸiklik gÃ¼nlÃ¼ÄŸÃ¼
- `changelog.json` - YapÄ±landÄ±rÄ±lmÄ±ÅŸ deÄŸiÅŸiklik verisi
- `.summarizer/` - Gizli sistem dosyalarÄ±

**ðŸŽ¯ Sonraki AdÄ±mlar:**
1. Python dosyalarÄ±nÄ±zda deÄŸiÅŸiklik yapÄ±n
2. `summarizer` komutunu tekrar Ã§alÄ±ÅŸtÄ±rÄ±n
3. Otomatik oluÅŸturulan deÄŸiÅŸiklik analizini inceleyin

**ðŸ’¡ Ä°pucu:** `summarizer --help` komutuyla tÃ¼m Ã¶zellikleri keÅŸfedin!"""

    elif project_type == "web":
        welcome_summary = f"""ðŸŒ **{project_name} Web Projesi BaÅŸlatÄ±ldÄ±**

**Proje TÃ¼rÃ¼**: Web GeliÅŸtirme Projesi  
**BaÅŸlatÄ±lma Tarihi**: {datetime.now().strftime('%d %B %Y')}  
**Summarizer Framework**: v2.0.0

**ðŸ“‹ Proje Ã–zeti:**
Web geliÅŸtirme projeniz Summarizer Framework ile entegre edildi. Frontend ve backend deÄŸiÅŸiklikleriniz otomatik olarak takip edilecek ve profesyonel deÄŸiÅŸiklik raporlarÄ± oluÅŸturulacak.

**ðŸ”§ Desteklenen Dosya TÃ¼rleri:**
- âœ… JavaScript/TypeScript dosyalarÄ± (.js, .ts, .jsx, .tsx)
- âœ… HTML/CSS dosyalarÄ± (.html, .css, .scss)
- âœ… Python backend dosyalarÄ± (.py)
- âœ… KonfigÃ¼rasyon dosyalarÄ± (package.json, requirements.txt)

**ðŸ“ Proje YapÄ±sÄ± HazÄ±rlandÄ±:**
- `CHANGELOG.md` - GeliÅŸtirme gÃ¼nlÃ¼ÄŸÃ¼
- `changelog.json` - API entegrasyonu iÃ§in JSON verisi
- `.summarizer/` - Gizli sistem dosyalarÄ±

**ðŸš€ Web Projesi Ã–zellikleri:**
- Frontend/Backend deÄŸiÅŸiklik ayrÄ±mÄ±
- Component bazÄ±nda analiz
- Dependencies deÄŸiÅŸiklik takibi
- Performance impact analizi

Bu projede deÄŸiÅŸiklik yaptÄ±ÄŸÄ±nÄ±zda, otomatik olarak akÄ±llÄ± analizler oluÅŸturulacak!"""

    else:
        welcome_summary = f"""ðŸ“ **{project_name} Projesi BaÅŸlatÄ±ldÄ±**

**Proje TÃ¼rÃ¼**: Genel YazÄ±lÄ±m Projesi  
**BaÅŸlatÄ±lma Tarihi**: {datetime.now().strftime('%d %B %Y')}  
**Summarizer Framework**: v2.0.0

**ðŸ“‹ HoÅŸ Geldiniz!**
Projeniz baÅŸarÄ±yla Summarizer Framework ile entegre edildi. ArtÄ±k tÃ¼m kod deÄŸiÅŸiklikleriniz otomatik olarak takip edilecek ve yapay zeka destekli analizler oluÅŸturulacak.

**ðŸ”§ Sistem Ã–zellikleri:**
- âœ… Dosya deÄŸiÅŸiklik takibi (.py, .js, .ts, .html, .css ve daha fazlasÄ±)
- âœ… Gemini AI ile kod analizi
- âœ… Otomatik impact level tespiti (Low/Medium/High/Critical)
- âœ… DeÄŸiÅŸiklik tipi kategorilendirmesi (Feature/Bug Fix/Refactor/Config)
- âœ… Markdown ve JSON format desteÄŸi

**ðŸ“Š Tracking Bilgileri:**
- **Toplam Dosya**: 0 (henÃ¼z deÄŸiÅŸiklik yok)
- **Son GÃ¼ncelleme**: {datetime.now().strftime('%H:%M:%S')}
- **Durum**: Aktif ve hazÄ±r âœ…

**ðŸŽ¯ Ä°lk KullanÄ±m:**
1. Herhangi bir dosyada deÄŸiÅŸiklik yapÄ±n
2. `summarizer` komutunu tekrar Ã§alÄ±ÅŸtÄ±rÄ±n  
3. Otomatik oluÅŸturulan analizi gÃ¶rÃ¼ntÃ¼leyin

**ðŸ’¡ Komutlar:**
- `summarizer --gui` - GÃ¶rsel arayÃ¼z
- `summarizer --status` - Sistem durumu
- `summarizer screenshot` - Ekran analizi

Projenizde her deÄŸiÅŸiklik yaptÄ±ÄŸÄ±nÄ±zda, akÄ±llÄ± Ã¶zetler otomatik oluÅŸturulacak!"""

    # Add the initial entry
    print("   ðŸŽ‰ Creating welcome entry for new project...")
    entry_id = json_manager.add_entry(
        ai_summary=welcome_summary,
        changed_files=[],
        impact_level=ImpactLevel.LOW,
        change_type=ChangeType.CONFIG,
        lines_added=0,
        lines_removed=0,
    )
    
    print("   ðŸ“ Project structure initialized:")
    print("      â€¢ CHANGELOG.md - Human readable changelog")  
    print("      â€¢ changelog.json - Structured data format")
    print("      â€¢ .summarizer/ - Internal tracking files")
    
    # Create initial README.md for new project
    try:
        print("      â€¢ README.md - Auto-generated project documentation")
        
        # Get AI client for enhanced README
        ai_client = None
        try:
            from ..services.request_manager import RequestManager
            request_manager = RequestManager()
            ai_client = request_manager.get_client("GeminiClient")
        except:
            pass  # Continue without AI enhancement
            
        readme_created = update_readme(project_root, ai_client)
        if readme_created:
            print("   ðŸ“ Professional README.md created")
        else:
            print("   âš ï¸  README.md creation skipped")
            
    except Exception as e:
        print(f"   âš ï¸  Could not create README.md: {e}")
        logger_changelog.warning(f"Error creating initial README.md: {e}")
    
    logger_changelog.info(f"Initial project entry created: {entry_id}")
    print(f"   âœ… Project initialized successfully!")


def _detect_project_type(project_root: Path) -> str:
    """Detect project type based on files in directory"""
    
    # Check for web project indicators
    web_files = ["package.json", "index.html", "main.js", "app.js", "webpack.config.js"]
    if any((project_root / f).exists() for f in web_files):
        return "web"
    
    # Check for Python project indicators
    python_files = ["requirements.txt", "setup.py", "pyproject.toml", "main.py"]
    py_files = list(project_root.glob("*.py"))
    if any((project_root / f).exists() for f in python_files) or len(py_files) > 0:
        return "python"
    
    # Default to general project
    return "general"


def get_recent_changelog_entries(project_root: Path, count: int = 5) -> list:
    """Get the most recent changelog entries from JSON format"""
    try:
        json_manager = JsonChangelogManager(project_root)
        entries = json_manager.get_entries(limit=count)
        return [entry.__dict__ for entry in entries]
    except Exception as e:
        logger_changelog.error(f"Error reading changelog entries: {e}")
        return []


def get_changelog_stats(project_root: Path) -> dict:
    """Get changelog statistics"""
    try:
        json_manager = JsonChangelogManager(project_root)
        return json_manager.get_stats()
    except Exception as e:
        logger_changelog.error(f"Error getting changelog stats: {e}")
        return {}


def export_changelog(project_root: Path, format_type: str = "json") -> str:
    """Export changelog in specified format"""
    try:
        json_manager = JsonChangelogManager(project_root)
        return json_manager.export_to_format(format_type)
    except Exception as e:
        logger_changelog.error(f"Error exporting changelog: {e}")
        return ""


def _get_ai_workflow_decision(gemini_client: Any, current_branch: str, summary: str, impact_level: ImpactLevel, changed_files: list) -> dict:
    """Use AI to decide the best workflow, branch strategy, and version management"""
    
    if not (gemini_client and gemini_client.is_ready()):
        # Fallback to rule-based decision
        return {
            "recommended_branch": "feature/auto-update" if current_branch == "main" else "current",
            "workflow": "standard",
            "reasoning": "AI unavailable, using standard workflow"
        }
    
    try:
        prompt = f"""As a senior DevOps engineer, analyze this Git workflow situation and recommend the best approach:

Current Branch: {current_branch}
Impact Level: {impact_level.value}
Changed Files: {', '.join(changed_files[:10])}
Summary: {summary[:200]}...

CRITICAL CONTEXT:
- If already on a feature/bugfix/hotfix/release branch, consider staying on it for continued development
- Only suggest a new branch if the current work is unrelated to the existing branch's purpose

Based on GitFlow best practices, determine:
1. Should we stay on current branch or create a new one?
2. If new branch needed, what type (feature/bugfix/release/hotfix)?
3. The recommended workflow to follow
4. Whether this change should go through PR or direct push

IMPORTANT RULES:
- NEVER allow direct commits to main branch
- If on feature/bugfix/hotfix/release branch, usually stay on it unless work is unrelated
- Critical changes should use hotfix branches
- High/Medium changes should use feature or release branches
- Low impact changes can use existing branches if appropriate
- Branch names MUST be in English, use descriptive English words based on the changed files
- For example: hotfix/git-workflow-fix, feature/ai-integration, release/version-update

Return a JSON object with:
{{
    "recommended_branch": "branch name in ENGLISH or 'current' to stay on {current_branch}",
    "branch_type": "feature|bugfix|release|hotfix|none",
    "workflow": "pr|direct|release",
    "target_branch": "where to merge (if PR workflow)",
    "reasoning": "brief explanation of your decision"
}}"""

        response = gemini_client.generate_simple_text(prompt)
        # Parse JSON from response
        import json
        import re
        
        # Extract JSON from response
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            decision = json.loads(json_match.group())
            
            # Validate and sanitize the decision
            if current_branch == "main" and decision.get("recommended_branch") == "current":
                # Override AI if it suggests staying on main
                decision["recommended_branch"] = f"release/v{VersionManager(Path.cwd()).get_current_version()}"
                decision["branch_type"] = "release"
                decision["workflow"] = "pr"
                decision["reasoning"] = "Overriding to prevent direct commits to main branch"
            
            return decision
        else:
            raise ValueError("Could not parse AI response")
            
    except Exception as e:
        logger_changelog.error(f"AI workflow decision failed: {e}")
        # Intelligent fallback based on current situation
        if current_branch == "main":
            # Generate English branch name based on changed files
            if changed_files:
                # Extract meaningful name from first changed file
                first_file = changed_files[0].replace('/', '-').replace('.py', '').replace('_', '-')
                branch_suffix = first_file.split('-')[-1] if '-' in first_file else 'update'
            else:
                branch_suffix = 'update'
                
            return {
                "recommended_branch": f"release/{branch_suffix}-{datetime.now().strftime('%Y%m%d')}",
                "branch_type": "release",
                "workflow": "pr",
                "target_branch": "main",
                "reasoning": "Protecting main branch from direct commits"
            }
        elif current_branch.startswith("feature/"):
            return {
                "recommended_branch": "current",
                "branch_type": "none",
                "workflow": "pr",
                "target_branch": "develop",
                "reasoning": "Standard feature branch workflow"
            }
        else:
            return {
                "recommended_branch": "current",
                "branch_type": "none", 
                "workflow": "direct",
                "reasoning": "Standard workflow for this branch type"
            }


# Test comment
